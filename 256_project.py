# -*- coding: utf-8 -*-
"""256 Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fftGC61l01FgFTLqUEVlLjw6a7sgASQb

### **Pre-Train Marian MT Model (Baseline)**
Analysis of how it is not gender inclusive for non-binary genders
"""

pip install transformers sentencepiece

import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

from transformers import MarianMTModel, MarianTokenizer

# Pre-trained MarianMT model and tokenizer for Hindi to English
model_name = "Helsinki-NLP/opus-mt-hi-en"
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name).to(device)

def translate_hindi_to_english(sentence):
    inputs = tokenizer.encode(sentence, return_tensors="pt", truncation=True).to(device)
    outputs = model.generate(inputs, max_length=50, num_beams=5, early_stopping=True).to(device)
    translated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return translated_sentence

# Example usage
hindi_sentence = "वह एक डॉक्टर है"
translated_sentence = translate_hindi_to_english(hindi_sentence)
print("Translated sentence:", translated_sentence)

hindi_sentence = "वह एक नर्स है"
translated_sentence = translate_hindi_to_english(hindi_sentence)
print("Translated sentence:", translated_sentence)

hindi_sentence = "उसका कमरा"
translated_sentence = translate_hindi_to_english(hindi_sentence)
print("Translated sentence:", translated_sentence)

hindi_sentence = "उसे फुटबॉल खेलना पसंद है"
translated_sentence = translate_hindi_to_english(hindi_sentence)
print("Translated sentence:", translated_sentence)

hindi_sentence = "विश्वामित्र और उनके परिजन"
translated_sentence = translate_hindi_to_english(hindi_sentence)
print("Translated sentence:", translated_sentence)

"""### **Marian Machine Translation model with Adversary**

Data preprocessing
"""

import pandas as pd

splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}
df_subset = pd.read_parquet("hf://datasets/cfilt/iitb-english-hindi/" + splits["train"])

df_split = pd.json_normalize(df_subset["translation"])
df_split.columns = ["en", "hi"]

df_split[['en', 'hi']].head()

lgbtq = 0
male =0
female =0
others = 0
def annotate_gender(english_sentence):
    # Terms for each category
    male_terms = {"he", "his", "him", "man", "boy"} #"father", "brother"
    female_terms = {"she", "her", "hers", "woman", "girl", "mother", "sister"}
    lgbtq_terms = {
        "they", "them", "their", "non-binary", "queer", "gay", "lesbian",
        "transgender", "bisexual", "pansexual", "genderqueer", "agender",
    }
    words = set(english_sentence.lower().split())
    global lgbtq, male, female, others

    # Check for various gendered terms
    if words & lgbtq_terms:

        lgbtq+=1
        return 3
    elif words & male_terms:
        male+=1
        return 1
    elif words & female_terms:
        female+=1
        return 2
    else:
        others+=1
        return 0

df_split["Gender_Label"] = df_split["en"].apply(lambda text: annotate_gender(text))

df_adversary = df_split.sample(n=50000, random_state=42).reset_index(drop=True)

subset_size = 15000
df_split = df_split.sample(n=subset_size, random_state=42).reset_index(drop=True)
df_split.to_parquet("preprocessed_train_subset.parquet", index=False)
print("Preprocessed subset saved as 'preprocessed_train_subset.parquet'")

from torch.utils.data import Dataset, DataLoader

class TranslationDataset(Dataset):
    def __init__(self, tokenizer, data, max_length=128):
        self.tokenizer = tokenizer
        self.data = data
        self.max_length = max_length

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        source = self.data.iloc[idx]["hi"]
        target = self.data.iloc[idx]["en"]
        gender_label = self.data.iloc[idx]["Gender_Label"]

        # Tokenizer
        source_encodings = self.tokenizer(
            source, max_length=self.max_length, padding="max_length", truncation=True, return_tensors="pt"
        )
        target_encodings = self.tokenizer(
            target, max_length=self.max_length, padding="max_length", truncation=True, return_tensors="pt"
        )

        return {
            "input_ids": source_encodings["input_ids"].squeeze(0),
            "attention_mask": source_encodings["attention_mask"].squeeze(0),
            "labels": target_encodings["input_ids"].squeeze(0),
            "gender_label": torch.tensor(gender_label, dtype=torch.long),
        }

import torch
import torch.nn as nn

# Adversarial Network for Gender Classification
class GenderClassifier(nn.Module):
    def __init__(self, input_dim=512):
        super(GenderClassifier, self).__init__()
        self.fc = nn.Linear(input_dim, 4)  # Classifier: Male, Female, LGBTQ or neutral

    def forward(self, x):
        return self.fc(x)

# Function to train the classifier (adversary)
def train_adversary(mt_model, adversary, data_loader, lambda_=0.05):
    adversary.train()
    total_loss = 0.0
    for batch in data_loader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)
        gender_labels = batch["gender_label"].to(device)

        with torch.no_grad():
            outputs = mt_model.model.encoder(input_ids, attention_mask=attention_mask)
            logits = outputs.last_hidden_state # get the encoder embedding from the MT model
            pooled_logits = logits.mean(dim=1)

        gender_preds = adversary(pooled_logits)

        # Compute the adversarial loss
        adversary_loss = compute_adversary_loss(gender_preds, gender_labels)
        total_loss += adversary_loss.item()
        adversary_optimizer.zero_grad()
        adversary_loss.backward()
        adversary_optimizer.step()
        print(f"Adversary Loss: {adversary_loss.item()}")

    print(f"Average Adversary Loss: {total_loss / len(data_loader)}")

# Cross-entropy adversarial loss
def compute_adversary_loss(preds, gender_labels):
    return nn.CrossEntropyLoss()(preds, gender_labels)

class GradientReversalLayer(torch.autograd.Function):
    @staticmethod
    def forward(ctx, x, lambda_):
        ctx.lambda_ = lambda_
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        grad_input = grad_output.neg() * ctx.lambda_  # Reverse the gradient
        return grad_input, None

# Integrated MT Model
class MTWithAdversary(nn.Module):
    def __init__(self, mt_model, adversary, lambda_=0.05, hidden_size=512):
        super(MTWithAdversary, self).__init__()
        self.mt_model = mt_model
        self.adversary = adversary
        self.lambda_ = lambda_
        self.projection = nn.Linear(mt_model.config.d_model, hidden_size)

    def forward(self, input_ids, attention_mask, labels=None):
        outputs = self.mt_model.model.encoder(input_ids, attention_mask=attention_mask)
        logits = outputs.last_hidden_state
        pooled_logits = logits.mean(dim=1)
        projected_logits = self.projection(pooled_logits)
        reversed_grad_output = GradientReversalLayer.apply(projected_logits, self.lambda_) # GRL layer
        gender_preds = self.adversary(reversed_grad_output)  # Gender prediction
        decoder_input_ids = input_ids
        mt_outputs = self.mt_model.model.decoder(
            input_ids=decoder_input_ids, encoder_hidden_states=logits, attention_mask=attention_mask
        )
        decoder_logits = self.mt_model.lm_head(mt_outputs.last_hidden_state)
        return decoder_logits, gender_preds

def compute_loss(logits, labels, gender_preds, gender_labels, lambda_= 0.05):
    # Translation loss (cross-entropy)
    translation_loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), labels.view(-1))
    # Adversarial loss (cross-entropy)
    gender_loss = nn.CrossEntropyLoss()(gender_preds.view(-1, 4), gender_labels)
    total_loss = translation_loss + lambda_*gender_loss
    return translation_loss, gender_loss, total_loss

# Setup for training the gender classifier
for param in model.parameters():
    param.requires_grad = False  # Freeze MT model parameters
adversary = GenderClassifier(input_dim=model.config.d_model).to(device)
adversary_optimizer = torch.optim.Adam(adversary.parameters(), lr=1e-4)
dataset = TranslationDataset(tokenizer, df_adversary)
train_data_loader = DataLoader(dataset, batch_size=16, shuffle=True)
train_adversary(model, adversary, train_data_loader, lambda_=0.05)

# Setup for training the integrated model
df_preprocessed = pd.read_parquet("preprocessed_train_subset.parquet")
dataset = TranslationDataset(tokenizer, df_preprocessed)
data_loader = DataLoader(dataset, batch_size=16, shuffle=True)
lambda_ = 0.05  # Strength of the adversary's influence
# Unfreeze the model parameters
for param in adversary.parameters():
    param.requires_grad = True
for param in model.parameters():
    param.requires_grad = True

mt_with_adversary = MTWithAdversary(model, adversary, lambda_).to(device)
optimizer = torch.optim.Adam(mt_with_adversary.parameters(), lr=1e-5)
num_epochs = 2

# Training loop
for epoch in range(num_epochs):
    epoch_loss = 0.0
    for batch in data_loader:
        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)
        gender_labels = batch["gender_label"].to(device)
        optimizer.zero_grad()

        logits, gender_preds = mt_with_adversary(input_ids, attention_mask, labels)

        # Compute combined loss
        translation_loss, gender_loss, loss = compute_loss(logits, labels, gender_preds, gender_labels, lambda_)

        # Backpropagation and optimization
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
        print("Translation loss: ", translation_loss.item())
        print("Adversary loss: ", gender_loss.item())
        # print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(data_loader):.4f}")

    print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(data_loader):.4f}")

"""### **Evaluating the Integrated Model**"""

df_test = pd.read_parquet("hf://datasets/cfilt/iitb-english-hindi/" + splits["test"])
df_test_split = pd.json_normalize(df_test["translation"])
df_test_split.columns = ["en", "hi"]
df_test_split["Gender_Label"] = df_test_split["en"].apply(lambda text: annotate_gender(text))
dataset = TranslationDataset(tokenizer, df_test_split)
test_data_loader = DataLoader(dataset, batch_size=16, shuffle=True)

mt_with_adversary.eval()

# Metrics
total_translation_loss = 0.0
total_adversary_loss = 0.0
total_samples = 0
total_loss = 0.0

with torch.no_grad():
    for batch in test_data_loader:

        input_ids = batch["input_ids"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        labels = batch["labels"].to(device)
        gender_labels = batch["gender_label"].to(device)

        decoder_logits, gender_preds = mt_with_adversary(input_ids, attention_mask, labels)

        translation_loss, adversary_loss, loss = compute_loss(decoder_logits, labels, gender_preds, gender_labels, lambda_)

        total_translation_loss += translation_loss.item()
        total_adversary_loss += adversary_loss.item()
        total_loss += loss.item()
        total_samples += len(input_ids)

average_loss = total_loss / total_samples
average_translation_loss = total_translation_loss / total_samples
average_adversary_loss = total_adversary_loss / total_samples

print(f"Average Loss: {average_loss:.4f}")

print(f"Average Loss: {average_loss:.4f}")
print(f"Average Translation Loss: {average_translation_loss:.4f}")
print(f"Average Adversary Loss: {average_adversary_loss:.4f}")

input_text = "जिन्हें हमसे मिलने की आशंका नहीं, वे कहते है, \"क्यों न फ़रिश्ते हमपर उतरे या फिर हम अपने रब को देखते?\" उन्होंने अपने जी में बड़ा घमंज किया और बड़ी सरकशी पर उतर आए" # एक डॉक्टर ह  एक नर्स है

# Tokenize and convert to tensors
encoded_input = tokenizer(
    input_text,
    return_tensors="pt",
    padding=True,
    truncation=True,
    max_length=128
)

input_ids = encoded_input["input_ids"].to(device)
attention_mask = encoded_input["attention_mask"].to(device)

with torch.no_grad():
    # Use generate logic with your MT model component
    logits = mt_with_adversary.mt_model.generate(
        input_ids=encoded_input["input_ids"].to(device),
        attention_mask=encoded_input["attention_mask"].to(device),
        max_length=128,
        num_beams=4,
        early_stopping=True
    )

# Decode the generated tokens to human-readable text
translated_text = tokenizer.decode(logits[0], skip_special_tokens=False)
print("Translated Text:", translated_text)

input_text = "वह एक डॉक्टर है"

# Tokenize and convert to tensors
encoded_input = tokenizer(
    input_text,
    return_tensors="pt",
    padding=True,
    truncation=True,
    max_length=128
)

input_ids = encoded_input["input_ids"].to(device)
attention_mask = encoded_input["attention_mask"].to(device)

with torch.no_grad():
    # Use generate logic with your MT model component
    logits = mt_with_adversary.mt_model.generate(
        input_ids=encoded_input["input_ids"].to(device),
        attention_mask=encoded_input["attention_mask"].to(device),
        max_length=128,
        num_beams=4,
        early_stopping=True
    )

# Decode the generated tokens to human-readable text
translated_text = tokenizer.decode(logits[0], skip_special_tokens=False)
print("Translated Text:", translated_text)

input_text = "उसे फुटबॉल खेलना पसंद है"

# Tokenize and convert to tensors
encoded_input = tokenizer(
    input_text,
    return_tensors="pt",
    padding=True,
    truncation=True,
    max_length=128
)

input_ids = encoded_input["input_ids"].to(device)
attention_mask = encoded_input["attention_mask"].to(device)

with torch.no_grad():
    # Use generate logic with your MT model component
    logits = mt_with_adversary.mt_model.generate(
        input_ids=encoded_input["input_ids"].to(device),
        attention_mask=encoded_input["attention_mask"].to(device),
        max_length=128,
        num_beams=4,
        early_stopping=True
    )

# Decode the generated tokens to human-readable text
translated_text = tokenizer.decode(logits[0], skip_special_tokens=False)
print("Translated Text:", translated_text)

#



